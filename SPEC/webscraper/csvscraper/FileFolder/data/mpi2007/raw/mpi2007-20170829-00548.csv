valid,1

"Full Results Table"

Benchmark,"Base # Ranks","Base Run Time","Base Ratio","Base Selected","Base Status","Peak # Ranks","Peak Run Time","Peak Ratio","Peak Selected","Peak Status",Description
104.milc,48,309.22664,5.061013,0,S,,,,,,"mref(ref) iteration #1"
104.milc,48,309.028376,5.06426,0,S,,,,,,"mref(ref) iteration #2"
104.milc,48,309.115991,5.062824,1,S,,,,,,"mref(ref) iteration #3"
107.leslie3d,48,943.766059,5.531032,0,S,,,,,,"mref(ref) iteration #1"
107.leslie3d,48,944.56505,5.526353,1,S,,,,,,"mref(ref) iteration #2"
107.leslie3d,48,945.305261,5.522026,0,S,,,,,,"mref(ref) iteration #3"
113.GemsFDTD,48,731.512612,8.623228,0,S,,,,,,"mref(ref) iteration #1"
113.GemsFDTD,48,732.121474,8.616057,0,S,,,,,,"mref(ref) iteration #2"
113.GemsFDTD,48,731.945526,8.618128,1,S,,,,,,"mref(ref) iteration #3"
115.fds4,48,392.919629,4.965392,0,S,,,,,,"mref(ref) iteration #1"
115.fds4,48,392.23939,4.974003,0,S,,,,,,"mref(ref) iteration #2"
115.fds4,48,392.646188,4.96885,1,S,,,,,,"mref(ref) iteration #3"
121.pop2,48,504.01156,8.190288,0,S,,,,,,"mref(ref) iteration #1"
121.pop2,48,502.781248,8.21033,1,S,,,,,,"mref(ref) iteration #2"
121.pop2,48,502.770707,8.210502,0,S,,,,,,"mref(ref) iteration #3"
122.tachyon,48,450.318254,6.211163,0,S,,,,,,"mref(ref) iteration #1"
122.tachyon,48,449.555474,6.221702,1,S,,,,,,"mref(ref) iteration #2"
122.tachyon,48,449.471034,6.22287,0,S,,,,,,"mref(ref) iteration #3"
126.lammps,48,563.691372,5.17127,0,S,,,,,,"mref(ref) iteration #1"
126.lammps,48,563.880048,5.169539,1,S,,,,,,"mref(ref) iteration #2"
126.lammps,48,563.967584,5.168737,0,S,,,,,,"mref(ref) iteration #3"
127.wrf2,48,767.709222,10.154886,0,S,,,,,,"mref(ref) iteration #1"
127.wrf2,48,770.265202,10.121189,0,S,,,,,,"mref(ref) iteration #2"
127.wrf2,48,769.016434,10.137625,1,S,,,,,,"mref(ref) iteration #3"
128.GAPgeofem,48,266.594621,7.745843,1,S,,,,,,"mref(ref) iteration #1"
128.GAPgeofem,48,266.898634,7.73702,0,S,,,,,,"mref(ref) iteration #2"
128.GAPgeofem,48,266.552558,7.747065,0,S,,,,,,"mref(ref) iteration #3"
129.tera_tf,48,425.87549,6.499552,0,S,,,,,,"mref(ref) iteration #1"
129.tera_tf,48,432.647333,6.397821,0,S,,,,,,"mref(ref) iteration #2"
129.tera_tf,48,426.165496,6.495129,1,S,,,,,,"mref(ref) iteration #3"
130.socorro,48,281.814126,13.544388,0,S,,,,,,"mref(ref) iteration #1"
130.socorro,48,282.150849,13.528224,1,S,,,,,,"mref(ref) iteration #2"
130.socorro,48,283.189293,13.478617,0,S,,,,,,"mref(ref) iteration #3"
132.zeusmp2,48,508.301859,6.10464,0,S,,,,,,"mref(ref) iteration #1"
132.zeusmp2,48,511.478214,6.06673,1,S,,,,,,"mref(ref) iteration #2"
132.zeusmp2,48,515.062846,6.024508,0,S,,,,,,"mref(ref) iteration #3"
137.lu,48,926.449766,3.967835,0,S,,,,,,"mref(ref) iteration #1"
137.lu,48,926.718557,3.966684,1,S,,,,,,"mref(ref) iteration #2"
137.lu,48,927.165538,3.964772,0,S,,,,,,"mref(ref) iteration #3"

"Selected Results Table"

Benchmark,"Base # Ranks","Base Run Time","Base Ratio","Base Selected","Base Status","Peak # Ranks","Peak Run Time","Peak Ratio","Peak Selected","Peak Status",Description
104.milc,48,309.115991,5.062824,1,S,,,,,NR,"SelectedIteration (base #3)"
107.leslie3d,48,944.56505,5.526353,1,S,,,,,NR,"SelectedIteration (base #2)"
113.GemsFDTD,48,731.945526,8.618128,1,S,,,,,NR,"SelectedIteration (base #3)"
115.fds4,48,392.646188,4.96885,1,S,,,,,NR,"SelectedIteration (base #3)"
121.pop2,48,502.781248,8.21033,1,S,,,,,NR,"SelectedIteration (base #2)"
122.tachyon,48,449.555474,6.221702,1,S,,,,,NR,"SelectedIteration (base #2)"
126.lammps,48,563.880048,5.169539,1,S,,,,,NR,"SelectedIteration (base #2)"
127.wrf2,48,769.016434,10.137625,1,S,,,,,NR,"SelectedIteration (base #3)"
128.GAPgeofem,48,266.594621,7.745843,1,S,,,,,NR,"SelectedIteration (base #1)"
129.tera_tf,48,426.165496,6.495129,1,S,,,,,NR,"SelectedIteration (base #3)"
130.socorro,48,282.150849,13.528224,1,S,,,,,NR,"SelectedIteration (base #2)"
132.zeusmp2,48,511.478214,6.06673,1,S,,,,,NR,"SelectedIteration (base #2)"
137.lu,48,926.718557,3.966684,1,S,,,,,NR,"SelectedIteration (base #2)"

SPECmpiM_base2007,6.678041,,6.678041
SPECmpiM_peak2007,"Not Run",,,,,,,"Not Run"

"Run number:",004

"System Vendor:",Cray
"System Name:","Cray XC30 (Intel Xeon E5-2697 v2)"
"Date tested:",Mar-2017
"MPI2007 License:",3440A
"Test sponsor:","Indiana University"
"Tested by:","Indiana University"
"Hardware avail:",Apr-2013
"Software avail:",Feb-2017


"Node Description: Big Red II Plus Node"

HARDWARE

"Number of nodes",1
"Uses of the node",compute
Vendor,Cray
Model,XC30
"CPU Name","Intel Xeon E5-2697 v2"
"CPU(s) orderable","1-2 chips"
"Chips enabled",2
"Cores enabled",24
"Cores per chip",12
"Threads per core",2
"CPU Characteristics","Intel Turbo Boost Technology disabled,"
,"Hyper-Threading enabled"
"CPU MHz",2700
"Primary Cache","32 KB I + 32 KB D on chip per core"
"Secondary Cache","256 KB I+D on chip per core"
"L3 Cache","30 MB I+D on chip per chip"
"Other Cache",None
Memory,"64 GB (8 x 8 GB 2Rx4 PC3-14900R-13, ECC)"
"Disk Subsystem",None
"Other Hardware",None
Adapter,"Mellanox Technologies MT27500 ConnectX-3"
"Number of Adapters",1
"Slot Type","PCIe x16 Gen 3"
"Data Rate",40Gbps
"Ports Used",1
"Interconnect Type","40 Gigabit Infiniband (QDR)"
Adapter,"Cray Aries"
"Number of Adapters",1
"Slot Type","PCIe x16 Gen 3"
"Data Rate","126 Gbps"
"Ports Used",4
"Interconnect Type",Aries

SOFTWARE

Adapter,"Mellanox Technologies MT27500 ConnectX-3"
"Adapter Driver",1.0-ofed1.5.4.1
"Adapter Firmware",2.33.5100
Adapter,"Cray Aries"
"Adapter Driver","Proprietary Cray_kgni"
"Adapter Firmware",v004.r091
"Operating System","SUSE Linux Enterprise Server 11 SP3 (x86_64),"
,"Cray Linux Environment 5.2"
,3.0.101-0.46.1_1.0502.8871-cray_ari_c
"Local File System",None
"Shared File System",Lustre
"System State",Multi-User
"Other Software","Slurm 15.08.12"


"Node Description: Data Capacitor II"

HARDWARE

"Number of nodes",2
"Uses of the node",fileserver
Vendor,DDN
Model,"DDN SFA12K"
"CPU Name","Intel Xeon CPU E5-2620"
"CPU(s) orderable","1-2 chips"
"Chips enabled",2
"Cores enabled",12
"Cores per chip",6
"Threads per core",1
"CPU Characteristics","Intel Turbo Boost Technology up to 2.50 GHz"
"CPU MHz",2000
"Primary Cache","32 KB I + 32 KB D on chip per core"
"Secondary Cache","256 KB I+D on chip per core"
"L3 Cache","15 MB I+D on chip per chip"
"Other Cache",None
Memory,"96 GB"
"Disk Subsystem","30 TB RAID 6, 10 (8 + 2) x 3 TB SAS"
,"Hitachi HUS724030ALS640, 7200RPM, 6.0Gbps"
"Other Hardware",None
Adapter,"Mellanox ConnectX MHQH29-XTC"
"Number of Adapters",1
"Slot Type","PCIe x8 Gen 2"
"Data Rate",40Gbps
"Ports Used",1
"Interconnect Type","40 Gigabit Infiniband (QDR)"

SOFTWARE

Adapter,"Mellanox ConnectX MHQH29-XTC"
"Adapter Driver",1.0-ofed1.5.4.1
"Adapter Firmware",2.9.1000
"Operating System","CentOS 6.2"
"Local File System",Linux/ext4
"Shared File System",lustre
"System State",Multi-User
"Other Software",None


"Interconnect Description: Infiniband (QDR)"

HARDWARE

Vendor,DDN
Model,"Mellanox SX6506"
"Switch Model","Mellanox SX6506"
"Number of Switches",1
"Number of Ports",108
"Data Rate","56 Gbps"
Firmware,"mellanox SX6506"
Topology,switched
"Primary Use","Lustre fileserver"


"Interconnect Description: Cray Aries"

HARDWARE

Vendor,Cray
Model,"Cray Aries"
"Switch Model","Cray Aries"
"Number of Switches",144
"Number of Ports",48
"Data Rate","126 Gb/s"
Firmware,v004.r091
Topology,Dragonfly
"Primary Use","MPI traffic"


"BENCHMARK DETAILS"

"Type of System",Homogeneous
"Total Compute Nodes",1
"Total Chips",2
"Total Cores",24
"Total Threads",48
"Total Memory","64 GB"
"Base Ranks Run",48
"Minimum Peak Ranks",--
"Maximum Peak Ranks",--
"C Compiler","Intel C Composer XE 2017 for Linux,"
,"Version 17.0.2.174 Build 20170213"
"C++ Compiler","Intel C++ Composer XE 2017 for Linux,"
,"Version 17.0.2.174 Build 20170213"
"Fortran Compiler","Intel Fortran Composer XE 2017 for Linux,"
,"Version 17.0.2.174 Build 20170213"
"Base Pointers",64-bit
"Peak Pointers",64-bit
"MPI Library","Cray MPI (MPT) 7.5.0"
"Other MPI Info",None
Pre-processors,No
"Other Software",None

"Submit Notes"

"The config file option 'submit' was used."
"submit = srun -c 1 -n $ranks -q $command"

"General Notes"

"130.socorro (base): ""nullify_ptrs"" src.alt was used."

"MPI startup command:"
"  srun command was used to start MPI jobs."

"export MPICH_NO_BUFFER_ALIAS_CHECK=true"
"  If set, the buffer alias error check for collectives is"
"  disabled. The MPI standard does not allow aliasing of type"
"  OUT or INOUT parameters on the same collective function"
"  call. The default is false."

"Job placement:"
"  Slurm is used for job placement."
"  Compute nodes are selected by Slurm."
"  No specific node selection is used."

"Base Compiler Invocation"
104.milc," cc"," cc"
107.leslie3d," ftn"," ftn"
113.GemsFDTD," ftn"," ftn"
115.fds4," cc"," ftn"," ftn"
121.pop2," cc"," ftn"," ftn"
122.tachyon," cc"," cc"
126.lammps," CC"," CC"
127.wrf2," cc"," ftn"," ftn"
128.GAPgeofem," cc"," ftn"," cc"," ftn"
129.tera_tf," ftn"," ftn"
130.socorro," cc"," ftn"," ftn"
132.zeusmp2," cc"," ftn"," ftn"
137.lu," ftn"," ftn"

"Base Portability Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2," -DSPEC_MPI_CASE_FLAG"
122.tachyon
126.lammps," -DMPICH_IGNORE_CXX_SEEK"
127.wrf2," -DSPEC_MPI_CASE_FLAG"," -DSPEC_MPI_LINUX"
128.GAPgeofem
129.tera_tf
130.socorro," -assume nostd_intent_in"
132.zeusmp2
137.lu

"Base Optimization Flags"
104.milc," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
107.leslie3d," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
113.GemsFDTD," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
115.fds4," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
121.pop2," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
122.tachyon," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
126.lammps," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
127.wrf2," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
128.GAPgeofem," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
129.tera_tf," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
130.socorro," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
132.zeusmp2," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"
137.lu," -O3"," -ansi-alias"," -no-prec-div"," -ipo"," -xhost"," -fp-model fast=2"

"Base Other Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Base Forbidden Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Base Unknown Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Peak Compiler Invocation"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Peak Portability Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Peak Optimization Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Peak Other Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Peak Forbidden Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu

"Peak Unknown Flags"
104.milc
107.leslie3d
113.GemsFDTD
115.fds4
121.pop2
122.tachyon
126.lammps
127.wrf2
128.GAPgeofem
129.tera_tf
130.socorro
132.zeusmp2
137.lu
----------------
"For questions about","this result, please","contact the tester.",
"For other inquiries,","please contact",webmaster@spec.org.,
"Copyright 2006-2010 Standard","Performance Evaluation",Corporation,
"Tested with SPEC MPI2007 ","v2.0.1.  Report","generated on ","Wed Sep 13 15:09:10 2017","by SPEC MPI2007 CSV","formatter v1463."
"Originally published on ","13 September 2017."
